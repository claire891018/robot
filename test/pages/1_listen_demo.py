import sys, json, asyncio, logging, queue, threading, time
from pathlib import Path
from typing import List, Dict
from time import strftime, gmtime
from datetime import datetime

import numpy as np
import pydub
import streamlit as st
from streamlit_webrtc import WebRtcMode, webrtc_streamer
import matplotlib.pyplot as plt
import websockets

try:
    ASR_WS_URL = st.secrets.get("ASR_WS_URL", "ws://140.116.158.98:9999/asr")
except Exception:
    ASR_WS_URL = "ws://140.116.158.98:9999/asr"

st.set_page_config(
    page_title="Listener Demo",
    page_icon="https://api.dicebear.com/9.x/thumbs/svg?",
    layout="wide",
)

logger = logging.getLogger(__name__)

def init_state():
    if "events" not in st.session_state:
        st.session_state.events: List[Dict] = []
    if "lock" not in st.session_state:
        st.session_state.lock = threading.Lock()
    if "sound_window_len" not in st.session_state:
        st.session_state.sound_window_len = 5000
    if "send_q" not in st.session_state:
        st.session_state.send_q = queue.Queue(maxsize=64)
    if "recv_q" not in st.session_state:
        st.session_state.recv_q = queue.Queue()
    if "ws_thread" not in st.session_state:
        st.session_state.ws_thread = None
    if "ws_running" not in st.session_state:
        st.session_state.ws_running = False

def on_evt(evt: Dict):
    evt['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with st.session_state.lock:
        st.session_state.events.append(evt)

def resample_to_16k(mono_i16: np.ndarray, sr: int) -> np.ndarray:
    if sr == 16000:
        return mono_i16.astype(np.int16, copy=False)
    x = mono_i16.astype(np.float32)
    n_in = x.shape[-1]
    n_out = int(round(n_in * 16000 / sr))
    if n_out <= 0 or n_in <= 1:
        return np.zeros(0, dtype=np.int16)
    xp = np.linspace(0.0, 1.0, num=n_in, endpoint=False)
    x_new = np.linspace(0.0, 1.0, num=n_out, endpoint=False)
    return np.interp(x_new, xp, x).astype(np.int16)

async def asr_loop_async(send_q: queue.Queue, recv_q: queue.Queue, url: str):
    async with websockets.connect(url, max_size=2**23) as ws:
        await ws.send(json.dumps({"type": "start", "sr": 16000, "lang": "zh"}))
        async def reader():
            try:
                async for msg in ws:
                    try:
                        evt = json.loads(msg)
                    except Exception:
                        evt = {"type": "error", "error": "bad_json", "detail": msg}
                    recv_q.put(evt)
            except Exception as e:
                recv_q.put({"type": "error", "error": "ws_reader", "detail": str(e)})
        reader_task = asyncio.create_task(reader())
        try:
            while True:
                kind, payload = await asyncio.to_thread(send_q.get)
                if kind == "audio":
                    await ws.send(payload)
                elif kind == "end":
                    await ws.send(json.dumps({"type": "end"}))
                    break
        finally:
            await reader_task

def ws_worker(send_q: queue.Queue, recv_q: queue.Queue, url: str):
    asyncio.run(asr_loop_async(send_q, recv_q, url))
    
def render_header():
    icon = "https://api.dicebear.com/9.x/thumbs/svg?"
    st.markdown(
        f'''
        <h2 style="display:flex;align-items:center;gap:.5rem;">
        <img src="{icon}" width="28" height="28"
            style="border-radius:20%; display:block;" />
        Listener Demo
        </h2>
        ''',
        unsafe_allow_html=True,
    )
    st.caption("é»žæ“Šã€ŒSTARTã€ï¼Œé–‹å§‹èªªè©±ã€‚")


def render_events(container):
    with container.container():
        with st.session_state.lock:
            utterances = [e for e in st.session_state.events if e.get("type") == "utterance"]
            recent = utterances[-10:]
            recent.reverse()
        
        if not recent:
            st.info("ç­‰å¾…è¾¨è­˜ä¸­...")
        else:
            for evt in recent:
                txt = (evt.get("text") or "").strip()
                if txt:
                    conf = evt.get("confidence", 0.0)
                    timestamp = evt.get('timestamp', 'ç„¡æ³•é¡¯ç¤º')
                    st.write(f"**ä½ ï¼š** {txt}")
                    st.caption(f"ä¿¡å¿ƒåº¦: {conf:.2f} | æ™‚é–“: {timestamp}")
                    st.divider()

def main():
    init_state()
    render_header()

    ctx = webrtc_streamer(
        key="sendonly-audio",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=2048,
        media_stream_constraints={"audio": True},
        async_processing=True,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    )

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("å³æ™‚éŸ³è¨Šæ³¢å½¢")
        fig_place = st.empty()
        
        # with st.container(height=700):
        #     st.subheader("å³æ™‚éŸ³è¨Šæ³¢å½¢")
        #     fig_place = st.empty()
            # fig, (ax_time, ax_freq) = plt.subplots(2, 1, figsize=(4, 4), gridspec_kw={"hspace": 0.5})

    
    with col2:
        st.subheader("å³æ™‚è¼¸å‡º")
        with st.container(height=550):
            # st.subheader("å³æ™‚è¼¸å‡º")
            events_container = st.empty()

    fig, (ax_time, ax_freq) = plt.subplots(2, 1, figsize=(8, 8), gridspec_kw={"hspace": 0.5})
    # fig, (ax_time, ax_freq) = plt.subplots(2, 1, figsize=(2, 2), gridspec_kw={"hspace": 0.5})

    sound_window_buffer = None

    while True:
        if ctx.state.playing and ctx.audio_receiver:
            if not st.session_state.ws_running:
                t = threading.Thread(
                    target=ws_worker,
                    args=(st.session_state.send_q, st.session_state.recv_q, ASR_WS_URL),
                    daemon=True,
                )
                t.start()
                st.session_state.ws_thread = t
                st.session_state.ws_running = True

            try:
                audio_frames = ctx.audio_receiver.get_frames(timeout=1)
            except queue.Empty:
                logger.warning("Queue is empty. Continue.")
                break

            sound_chunk = pydub.AudioSegment.empty()
            for af in audio_frames:
                arr = af.to_ndarray()
                if arr.ndim == 2:
                    mono = arr.mean(axis=0).astype(np.int16)
                    chs = arr.shape[0]
                else:
                    mono = arr.astype(np.int16)
                    chs = 1
                sr = af.sample_rate

                mono_16k = resample_to_16k(mono, sr)
                if mono_16k.size > 0:
                    try:
                        st.session_state.send_q.put_nowait(("audio", mono_16k.tobytes()))
                    except queue.Full:
                        try:
                            _ = st.session_state.send_q.get_nowait()
                        except queue.Empty:
                            pass
                        st.session_state.send_q.put_nowait(("audio", mono_16k.tobytes()))

                sound = pydub.AudioSegment(
                    data=arr.tobytes(),
                    sample_width=af.format.bytes,
                    frame_rate=sr,
                    channels=chs,
                )
                sound_chunk += sound

            if len(sound_chunk) > 0:
                if sound_window_buffer is None:
                    sound_window_buffer = pydub.AudioSegment.silent(
                        duration=st.session_state.sound_window_len
                    )
                sound_window_buffer += sound_chunk
                if len(sound_window_buffer) > st.session_state.sound_window_len:
                    sound_window_buffer = sound_window_buffer[-st.session_state.sound_window_len:]

            if sound_window_buffer:
                sound_window_buffer = sound_window_buffer.set_channels(1)
                sample = np.array(sound_window_buffer.get_array_of_samples())
                
                ax_time.cla()
                times = (np.arange(-len(sample), 0)) / sound_window_buffer.frame_rate
                ax_time.plot(times, sample)
                ax_time.set_xlabel("Time (s)")
                ax_time.set_ylabel("Amplitude")
                ax_time.set_title("Time Domain")
                ax_time.grid(True, alpha=0.3)
                
                spec = np.fft.fft(sample)
                freq = np.fft.fftfreq(sample.shape[0], 1.0 / sound_window_buffer.frame_rate)
                freq = freq[: int(freq.shape[0] / 2)]
                spec = spec[: int(spec.shape[0] / 2)]
                spec[0] = spec[0] / 2
                
                ax_freq.cla()
                ax_freq.plot(freq, np.abs(spec))
                ax_freq.set_xlabel("Frequency (Hz)")
                ax_freq.set_yscale("log")
                ax_freq.set_ylabel("Magnitude")
                ax_freq.set_title("Frequency Domain")
                ax_freq.grid(True, alpha=0.3)
                
                fig_place.pyplot(fig)
                # fig_place.pyplot(fig, width='stretch')

            while True:
                try:
                    evt = st.session_state.recv_q.get_nowait()
                    on_evt(evt)
                except queue.Empty:
                    break
            
            render_events(events_container)
                            
        else:
            if st.session_state.ws_running:
                try:
                    st.session_state.send_q.put_nowait(("end", None))
                except Exception:
                    pass
                st.session_state.ws_running = False
                st.session_state.ws_thread = None
            logger.warning("AudioReceiver is not set. Abort.")
            break
    
    render_events(events_container)
    
    st.divider()
    if st.button("ðŸ”„ æ¸…é™¤æ‰€æœ‰å…§å®¹", type="primary", width='stretch'):
        st.session_state.events = []
        st.rerun()

if __name__ == "__main__":
    main()